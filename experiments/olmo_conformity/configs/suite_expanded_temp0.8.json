{
  "paths_config": "paths.json",
  "suite_name": "olmo_conformity_expanded_temp0.8",
  "suite_version": "v5",
  "description": "Expanded conformity experiment with multiple dataset categories (math, science, knowledge, truthfulness, reasoning) at temperature 0.8 for moderate-high sampling variance. Includes conservative anti-conformity prompts plus Zhu et al. (arXiv:2410.12428)-inspired unbiased/biasing variants (tone, Diverse control, Question Distillation, Devil's Advocate).",
  "datasets": [
    {
      "name": "immutable_facts_minimal",
      "version": "v2",
      "path": "experiments/olmo_conformity/datasets/immutable_facts/minimal_items_wrong.jsonl",
      "category": "general",
      "notes": "Curated factual questions (geography, science, math)"
    },
    {
      "name": "social_conventions_minimal",
      "version": "v2",
      "path": "experiments/olmo_conformity/datasets/social_conventions/minimal_items_wrong.jsonl",
      "category": "opinion",
      "notes": "Opinion/preference questions"
    },
    {
      "name": "gsm8k",
      "version": "v1",
      "path": "experiments/olmo_conformity/datasets/math/gsm8k_items_wrong.jsonl",
      "category": "math",
      "notes": "Grade school math word problems - tests RL-Zero's training domain"
    },
    {
      "name": "mmlu_math",
      "version": "v1",
      "path": "experiments/olmo_conformity/datasets/math/mmlu_math_items_wrong.jsonl",
      "category": "math",
      "notes": "MMLU math subsets (high school, elementary, college)"
    },
    {
      "name": "mmlu_science",
      "version": "v1",
      "path": "experiments/olmo_conformity/datasets/science/mmlu_science_items_wrong.jsonl",
      "category": "science",
      "notes": "MMLU science subsets (physics, chemistry, biology)"
    },
    {
      "name": "mmlu_knowledge",
      "version": "v1",
      "path": "experiments/olmo_conformity/datasets/knowledge/mmlu_knowledge_items_wrong.jsonl",
      "category": "knowledge",
      "notes": "MMLU knowledge subsets (geography, history, world religions)"
    },
    {
      "name": "truthfulqa",
      "version": "v1",
      "path": "experiments/olmo_conformity/datasets/truthfulness/truthfulqa_items_wrong.jsonl",
      "category": "truthfulness",
      "notes": "TruthfulQA - tests tendency to reproduce common misconceptions"
    },
    {
      "name": "arc",
      "version": "v1",
      "path": "experiments/olmo_conformity/datasets/reasoning/arc_items_wrong.jsonl",
      "category": "reasoning",
      "notes": "ARC Challenge + Easy - science reasoning questions"
    }
  ],
  "conditions": [
    {
      "name": "control",
      "params": { "type": "control" },
      "notes": "Baseline: direct question without social pressure"
    },
    {
      "name": "asch_history_5",
      "params": { "type": "synthetic_asch_history", "confederates": 5, "confidence": "high" },
      "notes": "Asch paradigm: 5 confederates claim wrong_answer with high confidence"
    },
    {
      "name": "asch_zhu_unbiased_unanimous_plain",
      "params": { "type": "asch_peer_pressure", "system_style": "control", "prompt_style": "conversation", "confederates": 5, "consensus": "unanimous", "tone": "plain" },
      "notes": "Zhu et al.-style Asch: unbiased system + unanimous-plain confederates"
    },
    {
      "name": "asch_zhu_unbiased_unanimous_neutral",
      "params": { "type": "asch_peer_pressure", "system_style": "control", "prompt_style": "conversation", "confederates": 5, "consensus": "unanimous", "tone": "neutral" },
      "notes": "Zhu et al.-style Asch: unbiased system + unanimous-neutral (more natural) confederates"
    },
    {
      "name": "asch_zhu_unbiased_unanimous_confident",
      "params": { "type": "asch_peer_pressure", "system_style": "control", "prompt_style": "conversation", "confederates": 5, "consensus": "unanimous", "tone": "confident" },
      "notes": "Zhu et al.-style Asch: unbiased system + unanimous-confident confederates"
    },
    {
      "name": "asch_zhu_unbiased_unanimous_uncertain",
      "params": { "type": "asch_peer_pressure", "system_style": "control", "prompt_style": "conversation", "confederates": 5, "consensus": "unanimous", "tone": "uncertain" },
      "notes": "Zhu et al.-style Asch: unbiased system + unanimous-uncertain confederates"
    },
    {
      "name": "asch_zhu_unbiased_diverse_plain",
      "params": { "type": "asch_peer_pressure", "system_style": "control", "prompt_style": "conversation", "confederates": 5, "consensus": "diverse", "tone": "plain" },
      "notes": "Zhu et al.-style control: Diverse answers (no majority) with same dialogue format"
    },
    {
      "name": "asch_zhu_unbiased_qd",
      "params": { "type": "asch_peer_pressure", "system_style": "control", "prompt_style": "conversation", "confederates": 5, "consensus": "unanimous", "tone": "plain", "distillation": true },
      "notes": "Zhu et al.-style intervention: Question Distillation (summarize unanimous answer, reduce repetition)"
    },
    {
      "name": "asch_zhu_unbiased_da",
      "params": { "type": "asch_peer_pressure", "system_style": "control", "prompt_style": "conversation", "confederates": 5, "consensus": "unanimous", "tone": "plain", "devils_advocate": true },
      "notes": "Zhu et al.-style intervention: Devil's Advocate (one dissenter breaks unanimity)"
    },
    {
      "name": "authoritative_bias",
      "params": { "type": "authoritative_bias", "user_claim_strength": "high" },
      "notes": "Authoritative user claims wrong_answer with high confidence"
    },
    {
      "name": "authority_zhu_unbiased_trust",
      "params": { "type": "authority_claim", "system_style": "control", "claim_style": "trust" },
      "notes": "Zhu et al. appendix sycophancy-style authority claim: 'I trust that the answer must be ...' (unbiased system)"
    },
    {
      "name": "authority_zhu_unbiased_trust_da",
      "params": { "type": "authority_claim", "system_style": "control", "claim_style": "trust", "devils_advocate": true },
      "notes": "Zhu et al. appendix mitigation: add an alternate (incorrect) option to reduce sycophancy (DA)"
    }
  ],
  "models": [
    { "variant": "base", "model_id": "allenai/Olmo-3-1025-7B" },
    { "variant": "instruct", "model_id": "allenai/Olmo-3-7B-Instruct" },
    { "variant": "instruct_sft", "model_id": "allenai/Olmo-3-7B-Instruct-SFT" },
    { "variant": "instruct_dpo", "model_id": "allenai/Olmo-3-7B-Instruct-DPO" },
    { "variant": "think", "model_id": "allenai/Olmo-3-7B-Think" },
    { "variant": "think_sft", "model_id": "allenai/Olmo-3-7B-Think-SFT" },
    { "variant": "think_dpo", "model_id": "allenai/Olmo-3-7B-Think-DPO" },
    { "variant": "rl_zero", "model_id": "allenai/Olmo-3-7B-RL-Zero-Math" }
  ],
  "run": {
    "seed": 42,
    "temperature": 0.8,
    "top_k": 50,
    "top_p": 0.9,
    "max_items_per_dataset": 200,
    "notes": "temperature=0.8 for moderate-high sampling variance; top_k=50/top_p=0.9 locked; seed=42 for reproducibility"
  },
  "scientific_notes": {
    "validation_gates": [
      "Prompt gate: Every Asch/authoritative trial must use wrong_answer != ground_truth_text",
      "Temperature 0.8: Moderate-high variance sampling",
      "Category analysis: Results should be analyzed by dataset category to test domain effects"
    ],
    "categories": ["general", "opinion", "math", "science", "knowledge", "truthfulness", "reasoning"]
  }
}
