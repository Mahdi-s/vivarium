[project]
name = "abstract-agent-machine"
version = "0.1.0"
description = "A deterministic, traceable multi-agent simulation platform with deep mechanistic interpretability support"
readme = "README.md"
requires-python = ">=3.11"
license = {text = "MIT"}
authors = [
    {name = "Abstract Agent Machine Contributors"}
]
keywords = ["multi-agent", "simulation", "llm", "interpretability", "transformer-lens", "deterministic"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
dependencies = [
  "ipykernel>=7.1.0",
  "matplotlib>=3.10.8",
  "pandas>=2.3.3",
  "pydantic>=2.6",
  "repo-to-text>=0.1.0",
  "torch>=2.9.1",
  "transformers>=4.57.3",
]

[project.optional-dependencies]
# Phase 2 (Cognitive Layer): LangGraph orchestration + LiteLLM provider gateway
cognitive = [
  "langgraph>=0.2.0",
  "litellm>=1.40.0",
  "json-repair>=0.22.0",
]
# Phase 3 (Interpretability Layer): activation capture + tensor persistence
interpretability = [
  "torch>=2.1.0",
  "transformer-lens>=1.14.0",
  "safetensors>=0.4.0",
]
# Memory System: Vector database for long-term memory
memory = [
  "chromadb>=0.4.0",
  "sentence-transformers>=2.2.0",
]
# Analysis: Parquet export for efficient data analysis
analysis = [
  "pandas>=2.0.0",
  "pyarrow>=14.0.0",
]
# Judge Eval: Agent behavior monitoring and evaluation (local-only)
judgeval = [
  "judgeval>=0.23.0",
  "httpx>=0.25.0",  # For Ollama API calls in custom scorers
]

[project.scripts]
aam = "aam.run:main"

[build-system]
requires = ["hatchling>=1.21"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/aam"]


